{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-24T13:19:40.067090Z",
     "end_time": "2023-04-24T13:19:40.159336Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import unittest\n",
    "from IPython.display import display\n",
    "import scipy.stats as stats\n",
    "from pprint import pprint\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-24T13:19:40.067363Z",
     "end_time": "2023-04-24T13:19:40.353863Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assign raw data and plate diagram files from environment\n",
    "\n",
    "RAW_SAMPLE_1 = \"../data/maya_test/raw_counts_maya.xlsx\"\n",
    "RAW_SAMPLE_1_DIAGRAM = \"../data/maya_test/diagram_maya.xlsx\"\n",
    "\n",
    "# Read in the raw data and plate diagram as pandas dataframes\n",
    "df_data = pd.read_excel(RAW_SAMPLE_1, sheet_name=0)\n",
    "df_diagram = pd.read_excel(RAW_SAMPLE_1_DIAGRAM)\n",
    "\n",
    "\n",
    "# Test the raw data and plate diagram to make sure they are the correct size, should be 96 rows by 16 columns and 8 rows by 13 columns respectively always\n",
    "class TestStringMethods(unittest.TestCase):\n",
    "\n",
    "    def test_raw_data(self):\n",
    "        self.assertEqual(df_data.shape, (96, 15), f\"Raw data is {df_data.shape[0]} rows by {df_data.shape[1]} columns but should be 96 rows by 16 columns\")\n",
    "\n",
    "    def test_plate_diagram(self):\n",
    "        self.assertEqual(df_diagram.shape, (8, 13), f\"Plate diagram is {df_diagram.shape[0]} rows by {df_diagram.shape[1]} columns but should be 8 rows by 13 columns\")\n",
    "\n",
    "\n",
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)\n",
    "\n",
    "display(df_data)\n",
    "display(df_diagram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-24T13:19:40.067488Z",
     "end_time": "2023-04-24T13:19:40.432714Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the first column as the index, remove whitespace and add a space to the \"dup\" values\n",
    "df_diagram = df_diagram.set_index(df_diagram.columns[0])\n",
    "df_diagram = df_diagram.replace('\\s+', '', regex=True)\n",
    "df_diagram = df_diagram.replace(r'(?i)dup', ' dup', regex=True)\n",
    "\n",
    "\n",
    "# Create an empty sample map dictionary\n",
    "sample_map = {}\n",
    "\n",
    "for row in df_diagram.index:\n",
    "    for col in df_diagram.columns[1:]:\n",
    "        well_id = f\"{row}{int(col):02d}\"\n",
    "        sample_name = df_diagram.loc[row, col]\n",
    "        sample_map[well_id] = sample_name\n",
    "\n",
    "    \"\"\"Use rows and columns (besides the first one) to relate the well ID to the sample name.\n",
    "\n",
    "    For example, the first row name is A and the first column name is 1.\n",
    "    The well ID will be A01 and the sample name will the sample in that row/column.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "# Read in the raw qPCR data and map the well IDs to sample names using the dictionary\n",
    "df_data[\"Sample\"] = df_data[\"Well\"].map(sample_map)\n",
    "\n",
    "# Show Well, Sample, and Cq columns\n",
    "df_data[['Well', 'Sample', 'Cq']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-24T13:19:40.067570Z",
     "end_time": "2023-04-24T13:19:40.494618Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select relevant columns (Well, Cq, and Sample)\n",
    "df = df_data[['Well', 'Cq', 'Sample']].copy()\n",
    "\n",
    "# Create mtDNA1 and mtDNA2 columns\n",
    "df['mtDNA1'] = \"mtDNA1\"\n",
    "df['mtDNA2'] = \"mtDNA2\"\n",
    "\n",
    "# Arrange columns like this: \"Well\", \"Sample\", \"mtDNA1\", \"mtDNA2\", \"Cq\"\n",
    "df = df.loc[:,[\"Well\", \"Sample\", \"mtDNA1\", \"mtDNA2\", \"Cq\"]]\n",
    "\n",
    "# Drop rows with NA values\n",
    "df = df.dropna()\n",
    "\n",
    "# Show first 5 rows\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-24T13:19:40.067652Z",
     "end_time": "2023-04-24T13:19:40.652956Z"
    }
   },
   "outputs": [],
   "source": [
    "# set mtDNA1 and mtDNA2 values to Cq values by treating mtDNA1 as the Cq for the first sample and mtDNA2 as the Cq for the duplicate sample if it exists as \"Sample dup\"\n",
    "\n",
    "# Note, exactly \"Sample dup\" is used to avoid matching \"Sample dup **\" or any additions to the name\n",
    "\n",
    "for row, index in df.iterrows():\n",
    "    df.loc[row, 'mtDNA1'] = df.loc[row, 'Cq']\n",
    "    if df.loc[row, 'Sample'] + ' dup' in df['Sample'].values:\n",
    "        df.loc[row, 'mtDNA2'] = df.loc[df['Sample'] == df.loc[row, 'Sample'] + ' dup', 'Cq'].values[0]\n",
    "    else:\n",
    "        df.loc[row, 'mtDNA2'] = np.NAN\n",
    "\n",
    "\"\"\" Assign mtDNA1 and mtNDA2 value\n",
    "\n",
    "    For each row, set the mtDNA1 value to the Cq value and set the mtDNA2 value to the Cq value of the duplicate sample if it exists.\n",
    "\n",
    "    For example, if the sample name is \"D12\", set the mtDNA1 value to its Cq value and set the mtDNA2 value to the Cq value of \"D12 Dup\" (if it exists).\n",
    "\n",
    "    If the duplicate (\"D12 Dup\") does not exist, set the mtDNA2 value to NaN, which is then dropped later.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Drop the Cq column and drop NA values\n",
    "df = df.drop(columns=['Cq'])\n",
    "df = df.dropna()\n",
    "\n",
    "# calculate standard deviation of each row\n",
    "df['St.Dev'] = df[['mtDNA1', 'mtDNA2']].std(axis=1)\n",
    "\n",
    "# Show first 5 rows\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-24T13:19:40.067711Z",
     "end_time": "2023-04-24T13:19:40.653554Z"
    }
   },
   "outputs": [],
   "source": [
    "# Throw warnings for standard deviations greater than .22\n",
    "\n",
    "for row, index in df.iterrows():\n",
    "    if df.loc[row, 'St.Dev'] > .22:\n",
    "        print(f\"\\n Warning: Standard deviation for {df.loc[row, 'Sample']} is {round(df.loc[row, 'St.Dev'],ndigits=3)} \"\n",
    "              f\"(Sample 1: {round(df.loc[row, 'mtDNA1'],ndigits=3)} vs Sample 2: {round(df.loc[row, 'mtDNA2'], ndigits=2)}) \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-24T13:19:40.067771Z",
     "end_time": "2023-04-24T13:19:40.713322Z"
    }
   },
   "outputs": [],
   "source": [
    "#Drop index, sort by standard deviation (descending), and download the file\n",
    "df = df.sort_values(by=['St.Dev'], ascending=False)\n",
    "df.rename(columns = {'Sample' : 'Sample ID'}, inplace = True)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df\n",
    "# Uncomment to download the file\n",
    "# df.to_excel(\"50_gcr_random_name_test_output.xlsx\",\n",
    "#           index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-24T13:19:40.067895Z",
     "end_time": "2023-04-24T13:19:40.820597Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "REFERENCE_FILE = '../data/maya_test/maya_reference_file.xlsx'\n",
    "\n",
    "summary_file = pd.read_excel(REFERENCE_FILE, engine='openpyxl')\n",
    "\n",
    "# join the summary file with the data file on the sample name\n",
    "\n",
    "summary_file = summary_file.merge(df.loc[:, ('Sample ID', 'mtDNA1', 'mtDNA2')], on='Sample ID', how='left')\n",
    "\n",
    "summary_file.rename(columns = {'mtDNA1' : 'Telomere 1', 'mtDNA2' : 'Telomere 2'}, inplace = True)\n",
    "\n",
    "SRC_test_1 = [29.24,29.45,29.5,29.66,29.44,29.45,29.55,29.05,29.18,29.27,29.21,29.17,29.05,29.25,30.11,29.52,29.54,29.3,29.54,29.38,29.71,29.46,29.17,29.05,29.11,29.35,29.16,29.12,29.06,29.75,29.42,29.42,29.19,29.21,29.27,29.35\n",
    "]\n",
    "\n",
    "SRC_test_2 = [29.07, 29.41,29.5,29.38,29.73,29.59,29.63,29.08,29.18, 29.3,29.32,29.7,29,29.21,29.79,29.49,29.43,29.23,29.31,29.37,29.54,29.49,29.27,29.07,29.28,29.51,29.22,29.14,29.12,29.65,29.16,29.44,29.19,29.35,29.42,29.56]\n",
    "\n",
    "summary_file['SCR 1'] = SRC_test_1\n",
    "summary_file['SCR 2'] = SRC_test_2\n",
    "\n",
    "# check for NaN values and return string difference when not mapped\n",
    "for row, index in summary_file.iterrows():\n",
    "    if np.isnan(summary_file.loc[row, 'Telomere 1']):\n",
    "        print(f\"{summary_file.loc[row, 'Sample ID']} not found in data file, deleting row\")\n",
    "        summary_file.drop(index=row, axis=0, inplace=True)\n",
    "\n",
    "display(summary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-24T13:19:40.068015Z",
     "end_time": "2023-04-24T13:19:40.936661Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary_file['Avg Cq per sample, Telomere'] = summary_file.loc[:, ['Telomere 1', 'Telomere 2']].mean(axis=1)\n",
    "summary_file['Avg Cq per sample, SCR'] = summary_file.loc[:, ['SCR 1', 'SCR 2']].mean(axis=1)\n",
    "\n",
    "Avg_sq_per_target_telomere = summary_file['Avg Cq per sample, Telomere'].mean()\n",
    "Avg_sq_per_target_SCR = summary_file['Avg Cq per sample, SCR'].mean()\n",
    "\n",
    "summary_file['cCq per sample per target, Telomere'] = Avg_sq_per_target_telomere - summary_file['Avg Cq per sample, Telomere']\n",
    "\n",
    "summary_file['cCq per sample per target, SCR'] = Avg_sq_per_target_SCR - summary_file['Avg Cq per sample, SCR']\n",
    "\n",
    "summary_file['cCq Telomere - SCR'] = summary_file['cCq per sample per target, Telomere'] - summary_file['cCq per sample per target, SCR']\n",
    "\n",
    "summary_file['RQ, 2^dCq Telomere'] = 2**summary_file['cCq per sample per target, Telomere']\n",
    "summary_file['RQ, 2^dCq SCR'] = 2**summary_file['cCq per sample per target, SCR']\n",
    "\n",
    "summary_file['Normalized Expression, RQ Telo/RQ SCR'] = summary_file['RQ, 2^dCq Telomere'] / summary_file['RQ, 2^dCq SCR']\n",
    "\n",
    "display(summary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-24T13:19:40.068127Z",
     "end_time": "2023-04-24T13:19:40.964710Z"
    }
   },
   "outputs": [],
   "source": [
    "all_conditions = (summary_file['Full Tx'].unique())\n",
    "\n",
    "# calculate geomean for each condition\n",
    "sample_stats = []\n",
    "for condition in all_conditions:\n",
    "    condition_values = [sample for sample in summary_file.loc[summary_file['Full Tx'] == condition, 'Normalized Expression, RQ Telo/RQ SCR']]\n",
    "\n",
    "    condition_geomean = stats.gmean(condition_values)\n",
    "\n",
    "    sample_stats.append({'Condition': condition,\n",
    "                         'St.Dev': np.std(condition_values),\n",
    "                         'GeoMean': condition_geomean})\n",
    "\n",
    "print(\"\\n \\n Geo Means:\")\n",
    "pprint(sample_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-24T13:19:40.068253Z",
     "end_time": "2023-04-24T13:19:41.694289Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot a bar graph of each condition and their geomean\n",
    "\n",
    "conditions_summary = pd.DataFrame(sample_stats)\n",
    "\n",
    "sns.set_theme(style=\"white\")\n",
    "bar_plot = sns.barplot(x='Condition', y='GeoMean', data=conditions_summary)\n",
    "\n",
    "for index, row in conditions_summary.iterrows():\n",
    "    plt.errorbar(x=index, y=row['GeoMean'], yerr=row['St.Dev'], capsize=3, color='black', elinewidth=1, capthick=1)\n",
    "    \n",
    "for index, row in conditions_summary.iterrows():\n",
    "    bar_plot.text(index, row['GeoMean'] + row['St.Dev'] - 0.5, round(row['GeoMean'], 2), color='black', ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
